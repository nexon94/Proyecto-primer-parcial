{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto WordCloud",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ34RjasQeBR"
      },
      "source": [
        "%pip install BeautifulSoup4\n",
        "%pip install requests\n",
        "%pip install pandas\n",
        "%pip install WordCloud\n",
        "%pip install Colorama\n",
        "%pip install matplotlib-venn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UAHVs7P-lRZ"
      },
      "source": [
        "from bs4 import BeautifulSoup\r\n",
        "import string\r\n",
        "import requests\r\n",
        "import pandas as pd\r\n",
        "from wordcloud import WordCloud, STOPWORDS\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from colorama import init, Fore\r\n",
        "from google.colab import output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUDcnVieEtFj"
      },
      "source": [
        "\n",
        "def ciclo(g, p):\n",
        "    y = 0\n",
        "    while y < g:\n",
        "        y = y + 1\n",
        "        tex.write(\"\\t\"+p)\n",
        "\n",
        "def scraping(v,tagdict):\n",
        "    url = 'https://es.stackoverflow.com/users/'+v+'/?tab=tags'\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    while page.status_code!=200:\n",
        "        print(\"  ID de usuario no valido\")\n",
        "        x=input(\"Ingrese el id de usuario a extraer informacion: \\n  >>\")\n",
        "        url = 'https://es.stackoverflow.com/users/' + x + '/?tab=tags'\n",
        "        page = requests.get(url)\n",
        "        soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "        #Usuario\n",
        "    Tags = soup.find_all('a', class_='post-tag')\n",
        "    Points = soup.find_all('div', class_='answer-votes')\n",
        "    #print(User)\n",
        "    etiquetas = list()\n",
        "\n",
        "    for i in Tags:\n",
        "        etiquetas.append(i.text)\n",
        "\n",
        "    puntos = list()\n",
        "\n",
        "    for i in Points:\n",
        "        puntos.append(i.text.replace('k','000'))\n",
        "\n",
        "    for i in range(len(etiquetas)-1):\n",
        "      if int(puntos[i])>0:\n",
        "        tagdict[etiquetas[i]] = int(puntos[i])\n",
        "\n",
        "def wordcloud(tagdict):\n",
        "    x = 0\n",
        "    for x in tagdict:\n",
        "      if tagdict[x]>0:\n",
        "        g=tagdict[x]\n",
        "        p = x\n",
        "        ciclo(g, p)\n",
        "    tex.close()\n",
        "    with open(\"Datos.txt\", encoding='utf-8')as file: \n",
        "      text = file.read()\n",
        "      normal_word = r\"(?:\\w[\\w']+)\"\n",
        "      ascii_art = r\"(?:\\w[{punctuation}][{punctuation}]+)\".format(punctuation=string.punctuation)\n",
        "      c= r\"(?:\\w[{punctuation}]+)\".format(punctuation=string.punctuation)\n",
        "      emoji = r\"(?<![\\w{ascii_printable}])\".format(ascii_printable=string.printable)\n",
        "      regexp = r\"{normal_word}|{ascii_art}|{emoji}|{c}\".format( normal_word = normal_word,ascii_art=ascii_art,emoji=emoji,c=c)\n",
        "     \n",
        "      cloud = WordCloud(background_color=\"White\", collocations=False,regexp=regexp).generate(text)\n",
        "      plt.imshow(cloud)\n",
        "      plt.axis('off') \n",
        "      plt.show()\n",
        "\n",
        "def inicio():\n",
        "    v = input(\"\\n\\n  Ingrese el id de usuario a extraer informacion \\n  >> \")\n",
        "    tagdict = {}\n",
        "    scraping(v,tagdict)\n",
        "    print(\"\\n  * Se encontraron estas etiquetas: * \\n\")\n",
        "    print(tagdict)\n",
        "    print(\"\\n\")\n",
        "    if tagdict: # Actualizacion\n",
        "        wordcloud(tagdict)\n",
        "        print(\"     *Las etiquetas con 0 se ignoraron* \")\n",
        "    else:\n",
        "     print(\"  El usuario no cuenta con etiquetas.\\n  No se pudo generar el WordCloud :( \")\n",
        "print(\" Bienvenido\")\n",
        "while True:\n",
        "    output.clear()\n",
        "    tex = open(\"Datos.txt\", \"w\")\n",
        "    inicio()\n",
        "    x=str(input(\"\\n    Â¿continuar?  [1] Para Salir  ||   Cualquier tecla para continuar \\n  >> \"))\n",
        "    if x==\"1\":\n",
        "        output.clear()\n",
        "        fin()\n",
        "        break       \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}